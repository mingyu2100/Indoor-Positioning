import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import datetime

np.random.seed(777)
tf.set_random_seed(777)

x_DB = np.loadtxt('Geomagnetic_DB_1m.csv', delimiter=',', dtype=np.float32)
x_data = np.loadtxt('Geomagnetic_test_1m.csv', delimiter=',', dtype=np.float32)

# x = x_DB[0:2, 0:-1]
# print(x)
# print(x[0][0], x[0][1], x[0][2], x[0][3])
#
# y = []
# for i in range(0, 1):
#     for j in np.linspace(0, 1, 10):
#         for k in range(4):
#             y.append((x[i+1][k]-x[i][k]) * (j-i) + x[i][k])
#
# for i in range(0, len(y), 4):
#     for j in range(4):
#         print(y[i+j], end=' ')
#     print(end='\n')

db_classes = 90
read_num = 2
learning_rate = 0.01
training_epochs = 10

geo_m_db = x_DB[:, [0]]
geo_x_db = x_DB[:, [1]]
geo_y_db = x_DB[:, [2]]
geo_z_db = x_DB[:, [3]]

geo_m_test = x_data[:, [0]]
geo_x_test = x_data[:, [1]]
geo_y_test = x_data[:, [2]]
geo_z_test = x_data[:, [3]]

x_train = x_DB[:, 0:-1]
# print(type(x_train))
# print(x_train)
# print(x_train[1][0])

list_x_train = []  # linear interpolation(10개씩)
list_y_train = []
for i in range(0, db_classes - read_num + 1):
    list_y_train.append(i)
    for j in np.linspace(0, 1, 10):
        for k in range(4):
            list_x_train.append((x_train[i + 1][k] - x_train[i][k]) * j + x_train[i][k])

# for i in range(0, len(list_x_train), 4):
#     for j in range(4):
#         print(list_x_train[i + j], end=' ')
#     print(end='\n')

arr_x_train = np.array(list_x_train)
new_arr_x_train = arr_x_train.reshape(-1, 40)
# print(type(new_arr_x_train), new_arr_x_train.shape)
# print(new_arr_x_train)

arr_y_train = np.array(list_y_train)
new_arr_y_train = arr_y_train.reshape(-1, 1)
# print(type(new_arr_y_train), new_arr_y_train.shape)
# print(new_arr_y_train)

x_test = x_data[:, 0:-1]
list_x_test = []
for i in range(0, db_classes - read_num + 1):
    for j in np.linspace(0, 1, 10):
        for k in range(4):
            list_x_test.append((x_test[i + 1][k] - x_test[i][k]) * j + x_test[i][k])

# for i in range(0, len(list_x_test), 4):
#     for j in range(4):
#         print(list_x_test[i + j], end=' ')
#     print(end='\n')

arr_x_test = np.array(list_x_test)
new_arr_x_test = arr_x_test.reshape(-1, 40)

X = tf.placeholder(tf.float32, [None, 40], name='x-input')
Y = tf.placeholder(tf.int32, [None, 1], name='label')
Y_one_hot = tf.one_hot(Y, db_classes - read_num + 1)
Y_one_hot = tf.reshape(Y_one_hot, [-1, db_classes - read_num + 1])

with tf.name_scope('layer1'):
    # W1 = tf.Variable(tf.random_normal([40, 1024], name='weight1'))
    W1 = tf.get_variable('W1', shape=[40, 1024], initializer=tf.contrib.layers.xavier_initializer())
    b1 = tf.Variable(tf.random_normal([1024], name='bias1'))
    layer1 = tf.matmul(X, W1) + b1
    # layer1 = tf.nn.relu(layer1)

    # W1_hist = tf.summary.histogram('weights1', W1)
    # b1_hist = tf.summary.histogram('biases1', b1)
    # layer1_hist = tf.summary.histogram('layers1', layer1)

with tf.name_scope('layer2'):
    # W2 = tf.Variable(tf.random_normal([1024, db_classes - read_num + 1], name='weight2'))
    W2 = tf.get_variable('W2', shape=[1024, db_classes - read_num + 1], initializer=tf.contrib.layers.xavier_initializer())
    b2 = tf.Variable(tf.random_normal([db_classes - read_num + 1], name='bias2'))
    logits = tf.matmul(layer1, W2) + b2

    # W2_hist = tf.summary.histogram('weights2', W2)
    # b2_hist = tf.summary.histogram('biases2', b2)
    # layer2_hist = tf.summary.histogram('layers2', logits)

with tf.name_scope('cost'):
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot))
    # cost_summ = tf.summary.scalar('costs', cost)

with tf.name_scope('train'):
    # optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)
    optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)
    # optimizer = tf.train.AdadeltaOptimizer(0.01).minimize(cost)
    # optimizer = tf.train.AdagradOptimizer(0.01).minimize(cost)

with tf.name_scope('accuracy'):
    prediction = tf.argmax(logits, 1)
    correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    # accuracy_summ = tf.summary.scalar('accuracys', accuracy)

# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
sess = tf.Session()
# merged_summary = tf.summary.merge_all()
# writer = tf.summary.FileWriter('./logs', sess.graph)
sess.run(tf.global_variables_initializer())

t_start = datetime.datetime.now()

# for epoch in range(training_epochs):
for epoch in range(0):
    for step in range(10001):
        sess.run(optimizer, feed_dict={X: new_arr_x_train, Y: new_arr_y_train})
        # summary, _ = sess.run([merged_summary, optimizer], feed_dict={X: new_arr_x_train, Y: new_arr_y_train})
        # writer.add_summary(summary, global_step=step)

        if step % 2000 == 0:
            cost_val, acc_val = sess.run([cost, accuracy], feed_dict={X: new_arr_x_train, Y: new_arr_y_train})
            print('epoch: %2d' % epoch, 'Step: %5d' % step, 'cost: ', cost_val, 'acc: ', acc_val)

t_end = datetime.datetime.now()
print('Computation time: ' + str(t_end - t_start))

pred = sess.run(prediction, feed_dict={X: new_arr_x_train})
# print(pred, pred.shape)
for p, y in zip(pred, new_arr_y_train.flatten()):
    print('train_prediction: ', int(p), 'True: ', int(y))

pred = sess.run(prediction, feed_dict={X: new_arr_x_test})
for p, y in zip(pred, new_arr_y_train.flatten()):
    print('test_prediction: ', int(p), 'True: ', int(y))

acc_val = sess.run(accuracy, feed_dict={X: new_arr_x_test, Y: new_arr_y_train})
print('acc: ', acc_val)

length_db = range(db_classes)
Interpol_length_db = range(len(new_arr_x_train) * 10)

plt.figure()
# 기존 보간법 사용하기 전 DB 그래프
plt.plot(length_db, geo_m_db, 'ro-', label='m_db')
plt.plot(length_db, geo_x_db, 'ro-', label='x_db')
plt.plot(length_db, geo_y_db, 'ro-', label='y_db')
plt.plot(length_db, geo_z_db, 'ro-', label='z_db')

# test 그래프
plt.plot(length_db, geo_m_test, 'bs--', label='m_test')
plt.plot(length_db, geo_x_test, 'bs--', label='x_test')
plt.plot(length_db, geo_y_test, 'bs--', label='y_test')
plt.plot(length_db, geo_z_test, 'bs--', label='z_test')

plt.grid()
plt.legend()
plt.xlabel('meter')
plt.ylabel('value')
plt.title('Geomagnetic')

Interpor_m, Interpor_x, Interpor_y, Interpor_z = [], [], [], []
for i in range(len(new_arr_x_train)):
    for j in range(len(new_arr_x_train[0])):
        if j % 4 == 0:
            Interpor_m.append(new_arr_x_train[i, j])
        elif j % 4 == 1:
            Interpor_x.append(new_arr_x_train[i, j])
        elif j % 4 == 2:
            Interpor_y.append(new_arr_x_train[i, j])
        else:
            Interpor_z.append(new_arr_x_train[i, j])
# print(Interpor_m)
# print(Interpor_x)
# print(Interpor_y)
# print(Interpor_z)

# 보간법 사용 후 그래프
plt.figure()
plt.plot(Interpol_length_db, Interpor_m, 'o', label='Interpol_m_db')
plt.plot(Interpol_length_db, Interpor_x, 'o', label='Interpol_x_db')
plt.plot(Interpol_length_db, Interpor_y, 'o', label='Interpol_y_db')
plt.plot(Interpol_length_db, Interpor_z, 'o', label='Interpol_z_db')

plt.grid()
plt.legend()
plt.xlabel('centimeter')
plt.ylabel('value')
plt.title('Geomagnetic')
plt.show()

sess.close()